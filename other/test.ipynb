{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "end\n"
     ]
    },
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x7be43a187b00>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 22\u001b[0m\n\u001b[1;32m     17\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124mStyle: Joan Cornellà.\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124mContent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontent\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     21\u001b[0m image_bytes \u001b[38;5;241m=\u001b[39m query({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt})\n\u001b[0;32m---> 22\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/PIL/Image.py:3186\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3184\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m accept_warnings:\n\u001b[1;32m   3185\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[0;32m-> 3186\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(\n\u001b[1;32m   3187\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[1;32m   3188\u001b[0m )\n",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x7be43a187b00>"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import io\n",
    "from PIL import Image\n",
    "    \n",
    "content = 'A cat sit on the sofa.'\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "headers = {\"Authorization\": f\"Bearer {user_access_token}\"}\n",
    "\n",
    "def query(payload):\n",
    "    print('start')\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    print('end')\n",
    "    return response.content\n",
    "\n",
    "prompt = f'''\n",
    "Style: Joan Cornellà.\n",
    "Content: {content}\n",
    "'''\n",
    "image_bytes = query({\"inputs\": prompt})\n",
    "image = Image.open(io.BytesIO(image_bytes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024>,\n",
       " <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024>,\n",
       " <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024>,\n",
       " <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def text_to_images(story_info, user_access_token):\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "    headers = {\"Authorization\": f\"Bearer {user_access_token}\"}\n",
    "    \n",
    "    def query(payload):\n",
    "        print('start')\n",
    "        response = requests.post(API_URL, headers=headers, json=payload)\n",
    "        print('end')\n",
    "        return response.content\n",
    "    \n",
    "    illustration_keys = ['illustration 1', 'illustration 2', 'illustration 3', 'illustration 4']\n",
    "    images = []\n",
    "    for illustration_key in illustration_keys:\n",
    "        content = story_info[illustration_key]\n",
    "        \n",
    "        prompt = f'''\n",
    "        Style: Joan Cornellà.\n",
    "        Content: {content}\n",
    "        '''\n",
    "        image_bytes = query({\"inputs\": prompt})\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "        images.append(image)\n",
    "    return images\n",
    "\n",
    "\n",
    "story_info = {'paragraph 1': 'Little boy Li dreamed of flying like a bird, so he wished upon a star to become one.', 'illustration 1': \"A young boy with outstretched arms and closed eyes, surrounded by stars in the night sky. The illustration should capture the sense of wonder and magic in Li's dream.\", 'paragraph 2': 'Suddenly, his body began to transform into a bird! Feathers grew from his skin, and wings sprouted from his shoulders.', 'illustration 2': 'A boy with feather-covered arms and wings, looking surprised but thrilled at his new avian form. The illustration should show the transformation process in action.', 'paragraph 3': 'Li soared through the sky, feeling free and exhilarated like never before. He chirped happily as he flew over fields and forests.', 'illustration 3': \"A bird-like boy flying high above a picturesque landscape, with rolling hills and trees below. The illustration should convey the joy and freedom of Li's new avian life.\", 'paragraph 4': 'But when the sun rose, Li realized he missed his family and friends back home. He wished again upon a star to return to human form.', 'illustration 4': \"A bird-like boy looking wistful as he gazes at a rising sun, with a village or town in the background. The illustration should show the bittersweet feeling of leaving behind one's newfound freedom for the comfort and security of home.\", 'title': '變成鳥'}\n",
    "text_to_images(story_info, user_access_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/webapp/.local/lib/python3.10/site-packages/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.\n",
      "  warnings.warn(\"`gpu` will be deprecated. Please use `tts.to(device)` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
      " > Using model: xtts\n",
      " > Text splitted to sentences.\n",
      "['A cat sit on the floor']\n",
      " > Processing time: 0.3255496025085449\n",
      " > Real-time factor: 0.1316069363323815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/webapp/AI_PictureBooks_Web/website/model/a.mp3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\", gpu=True)\n",
    "\n",
    "text = 'A cat sit on the floor'\n",
    "lang = 'en'\n",
    "\n",
    "speaker_path = '/home/webapp/AI_PictureBooks_Web/website/model/speaker.mp3'\n",
    "speech_file_path = f\"/home/webapp/AI_PictureBooks_Web/website/model/a.mp3\"\n",
    "tts.tts_to_file(text=text, file_path=speech_file_path, speaker_wav=speaker_path, language=lang)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
